# **Detecting Hallucinations in Large Language Models via Structural Entropy**  

## **Project Overview**  
This repository contains the code implementation for the paper *"Detecting Hallucinations in Large Language Models via Structural Entropy"*, which aims to detect hallucinated content in LLM-generated text. The project consists of two main modules:  
1. **Long-form text hallucination detection**  
2. **Sentence-level hallucination detection**  

## **Project Structure**  
```
├── README.md  
├── environment.yml  
├── requirements.txt  
├── long_form_structural_entropy/  
│   ├── DeepSeek_R1_data.py  
│   ├── HCSE.py  
│   ├── eval_utils.py  
│   ├── main.py  
│   ├── o1_data.py  
│   ├── run_record/  
│   └── utils.py  
└── sentence_structural_entropy/  
    ├── analyze_results.py  
    ├── run_record/  
    ├── sample_answers.py  
    ├── src/  
    └── uncertainty_quantification.py  
```  

## **Environment Setup**  

### **Dependency Installation**  
Install dependencies using `requirements.txt`:  
```powershell  
pip install -r requirements.txt  
```  

### **Conda Environment Setup**  
Configure the environment using `environment.yml`:  
```powershell  
conda env create -f environment.yml  
```  

## **System Requirements**  

- **Recommended Python version**: 3.11 (Core dependencies include PyTorch 2.1).  
- **Hardware**: NVIDIA H100 GPU recommended for reasonable inference speed.  
- **OS**: Developed and tested on **Ubuntu 20.04.6 LTS**, but should be compatible with other major operating systems.  

## **Module Descriptions**  

### **1. Long-form Structural Entropy (`long_form_structural_entropy/`)**  
Detects hallucinations in long-form LLM-generated text.  

#### **Key Files**  
- `DeepSeek_R1_data.py`, `o1_data.py`: Construct fine-grained hallucination datasets generated by **DeepSeek-R1** and **OpenAI o1**.  
- `HCSE.py`: Implements **Hierarchical Clustering Structural Entropy (HCSE)** calculation.  
- `main.py`: Main entry point (LLM calls, adjacency matrix construction, structural entropy calculation, and evaluation).  
- `eval_utils.py`, `utils.py`: Evaluation and utility functions.  
- **Outputs**: Saved in `run_record/`.  

#### **Execution Steps**  
1. Install dependencies and activate the environment.  
2. Run the main script:  
   ```powershell  
   python long_form_structural_entropy/main.py  
   ```  
3. Results are saved in `long_form_structural_entropy/run_record/`.  

---

### **2. Sentence-level Structural Entropy (`sentence_structural_entropy/`)**  
Detects hallucinations at the sentence level, focusing on **uncertainty quantification** and entropy-based metrics.  

#### **Key Files**  
- `analyze_results.py`: Analyzes uncertainty metrics (e.g., AUROC, structural entropy).  
- `uncertainty_quantification.py`: Implements uncertainty quantification.  
- `sample_answers.py`: Samples answers from LLMs.  
- `src/`: Contains submodules for data processing, models, and utilities.  
- **Outputs**: Saved in `run_record/`.  

#### **Execution Steps**  
1. Install dependencies and activate the environment.  
2. **Sample answers**:  
   ```powershell  
   python sentence_structural_entropy/sample_answers.py  
   ```  
3. **Run uncertainty quantification**:  
   ```powershell  
   python sentence_structural_entropy/uncertainty_quantification.py --runid <run_id>  
   ```  
4. **Analyze results**:  
   ```powershell  
   python sentence_structural_entropy/analyze_results.py --runid <run_id>  
   ```  
5. Results are saved in `sentence_structural_entropy/run_record/`.  

---

## **Run Records**  
The `run_record/` folders in both modules store intermediate outputs (charts, metrics, etc.) for reproducibility and analysis.  

## **Notes**  
- Ensure all dependencies are installed before execution.  
- To access the datasets (`DeepSeek_R1_data.py`, `o1_data.py`), contact us at **xtaozhao@163.com**.  
- An **API key** is required for LLM calls.  

